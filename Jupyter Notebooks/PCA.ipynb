{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source: https://www.kaggle.com/tilii7/dimensionality-reduction-pca-tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    import matplotlib.cm as cm\n",
    "    from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading files ...\n",
      "('\\nThere are 2 unique target valuess in this dataset:', array([0, 1], dtype=int8))\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading files ...')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "X = train.drop(['id', 'target'], axis=1).values\n",
    "y = train['target'].values.astype(np.int8)\n",
    "target_names = np.unique(y)\n",
    "print('\\nThere are %d unique target valuess in this dataset:' % (len(target_names)), target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis identifies the combination of components (directions in the feature space) that account for the most variance in the data. This is useful for visualizing high dimensional data using only components that account for most of the variance in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n Shape of processed train data:', (595212L, 227L))\n",
      "(' Shape of processed test data:', (892816L, 227L))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Creating dummy variables for categorical data\n",
    "\n",
    "def scale_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n",
    "\n",
    "X = train.drop(['id', 'target'], axis=1)\n",
    "test.drop(['id'], axis=1, inplace=True)\n",
    "n_train = X.shape[0]\n",
    "train_test = pd.concat((X, test)).reset_index(drop=True)\n",
    "col_to_drop = X.columns[X.columns.str.endswith('_cat')]\n",
    "col_to_dummify = X.columns[X.columns.str.endswith('_cat')].astype(str).tolist()\n",
    "\n",
    "for col in col_to_dummify:\n",
    "    dummy = pd.get_dummies(train_test[col].astype('category'))\n",
    "    columns = dummy.columns.astype(str).tolist()\n",
    "    columns = [col + '_' + w for w in columns]\n",
    "    dummy.columns = columns\n",
    "    train_test = pd.concat((train_test, dummy), axis=1)\n",
    "\n",
    "train_test.drop(col_to_dummify, axis=1, inplace=True)\n",
    "\n",
    "# Scaling the data\n",
    "\n",
    "train_test_scaled, scaler = scale_data(train_test)\n",
    "X = np.array(train_test_scaled[:n_train, :])\n",
    "test = np.array(train_test_scaled[n_train:, :])\n",
    "print('\\n Shape of processed train data:', X.shape)\n",
    "print(' Shape of processed test data:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running PCA again ...\n",
      "Explained variance: 0.6231\n",
      "Individual variance contributions:\n",
      "0.074084070101\n",
      "0.0618868203631\n",
      "0.0559539511796\n",
      "0.0427607611418\n",
      "0.0359086048879\n",
      "0.0345707250307\n",
      "0.0314658500583\n",
      "0.0285582078293\n",
      "0.0255109028989\n",
      "0.0252506880295\n",
      "0.0245827886253\n",
      "0.0241400322075\n",
      "0.0238642769192\n",
      "0.0232114066023\n",
      "0.021035114187\n",
      "0.0209135028964\n",
      "0.020064977449\n",
      "0.0189478800073\n",
      "0.0162507118409\n",
      "0.014169058539\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'colors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ef07bed18ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, s=1,\n\u001b[0;32m     16\u001b[0m                 alpha=.8, label=target_name, marker='.')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'colors' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b183d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Doing PCA\n",
    "n_comp = 20\n",
    "print('\\nRunning PCA again ...')\n",
    "pca = PCA(n_components=n_comp, svd_solver='full', random_state=1001)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print('Explained variance: %.4f' % pca.explained_variance_ratio_.sum())\n",
    "\n",
    "print('Individual variance contributions:')\n",
    "for j in range(n_comp):\n",
    "    print(pca.explained_variance_ratio_[j])\n",
    "\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=color, s=1,\n",
    "                alpha=.8, label=target_name, marker='.')\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=3)\n",
    "plt.title(\n",
    "        \"Scatter plot of the training data projected on the 1st \"\n",
    "        \"and 2nd principal components\")\n",
    "plt.xlabel(\"Principal axis 1 - Explains %.1f %% of the variance\" % (\n",
    "        pca.explained_variance_ratio_[0] * 100.0))\n",
    "plt.ylabel(\"Principal axis 2 - Explains %.1f %% of the variance\" % (\n",
    "        pca.explained_variance_ratio_[1] * 100.0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is visible from this plot that there are very few clearly defined clusters of 1s and there is no clear separation\n",
    "between 0s and 1s."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
